{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T13:39:59.421609Z",
     "start_time": "2025-09-16T13:39:56.284164Z"
    }
   },
   "source": [
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForMaskedLM,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/venv/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:44:00.644044Z",
     "start_time": "2025-09-16T13:44:00.642221Z"
    }
   },
   "cell_type": "markdown",
   "source": "# BERT: Masked Language Model",
   "id": "6b8658b7453e0f3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:45:30.779472Z",
     "start_time": "2025-09-16T13:45:30.777422Z"
    }
   },
   "cell_type": "code",
   "source": "text = \"Life is like a [MASK] of chocolates.\"",
   "id": "26ac762da741072f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:48:15.074993Z",
     "start_time": "2025-09-16T13:47:55.394748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ],
   "id": "3bd81400fa86cdd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:51:43.645640Z",
     "start_time": "2025-09-16T13:51:43.642695Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_input = tokenizer(text, return_tensors='pt')",
   "id": "60b7dff7e696d450",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:52:29.271847Z",
     "start_time": "2025-09-16T13:52:29.264574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('input:', encoded_input['input_ids'])\n",
    "print('attention_mask:', encoded_input['attention_mask'])"
   ],
   "id": "f05439bd52021ee5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[ 101, 2166, 2003, 2066, 1037,  103, 1997, 7967, 2015, 1012,  102]])\n",
      "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:53:50.051771Z",
     "start_time": "2025-09-16T13:53:50.045454Z"
    }
   },
   "cell_type": "code",
   "source": "print(tokenizer.decode(7967))",
   "id": "7c6a4b1cd3155af8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocolate\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:55:02.846409Z",
     "start_time": "2025-09-16T13:55:02.842791Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "274aeb09b2f03f47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:03:25.999655Z",
     "start_time": "2025-09-16T14:03:25.966514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_output = model(**encoded_input)\n",
    "output = model_output['logits']\n",
    "\n",
    "print(output.shape)"
   ],
   "id": "d16073e024ac10bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 30522])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:06:09.711144Z",
     "start_time": "2025-09-16T14:06:09.705074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = encoded_input['input_ids'][0].tolist()\n",
    "masked_index = tokens.index(tokenizer.mask_token_id)\n",
    "logits = output[0, masked_index, :]\n",
    "print(logits.shape)"
   ],
   "id": "c1d475b370449d11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:08:49.422411Z",
     "start_time": "2025-09-16T14:08:49.414585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probs = logits.softmax(dim=-1)\n",
    "values, predictions = probs.topk(5)\n",
    "sequence = tokenizer.decode(predictions)\n",
    "print('Top 5 predictions:', sequence)\n",
    "print(values)"
   ],
   "id": "6bffe9f8fd5937cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predictions: box bag bowl jar cup\n",
      "tensor([0.1764, 0.1688, 0.0419, 0.0336, 0.0262], grad_fn=<TopkBackward0>)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Casual LM",
   "id": "8aceab17bf81bb2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:14:51.156212Z",
     "start_time": "2025-09-16T14:14:28.238484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ],
   "id": "1c7a8d8a3afbcc3c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:15:29.038391Z",
     "start_time": "2025-09-16T14:15:29.033347Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "d55a79112d55e9f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:22:19.048408Z",
     "start_time": "2025-09-16T14:22:19.039712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Swimming at the beach is\"\n",
    "model_inputs = tokenizer(text, return_tensors='pt')\n",
    "model_inputs"
   ],
   "id": "aaf60d64c724c599",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[10462, 27428,   379,   262, 10481,   318]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:31.917199Z",
     "start_time": "2025-09-16T14:23:31.797925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = model(**model_inputs)\n",
    "next_token_logits = output.logits[:, -1, :]\n",
    "next_token = torch.argmax(next_token_logits, dim=-1)\n",
    "print(next_token)"
   ],
   "id": "f42d37a9d99b7295",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([257])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:53.345862Z",
     "start_time": "2025-09-16T14:23:53.342350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_inputs['input_ids'] = torch.cat([model_inputs['input_ids'], next_token[:, None]], dim=-1)\n",
    "model_inputs[\"attention_mask\"] = torch.cat([model_inputs['attention_mask'], torch.tensor([[1]])], dim=-1)\n",
    "print(model_inputs)"
   ],
   "id": "f6e07cb56e6cf142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[10462, 27428,   379,   262, 10481,   318,   257]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:24:13.417246Z",
     "start_time": "2025-09-16T14:24:13.414937Z"
    }
   },
   "cell_type": "code",
   "source": "print(tokenizer.decode(model_inputs['input_ids'][0]))",
   "id": "dd8fe357d7c58c92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swimming at the beach is a\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:26:43.337942Z",
     "start_time": "2025-09-16T14:26:43.302341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = model(**model_inputs)\n",
    "next_token_logits = output.logits[:, -1, :]\n",
    "next_token = torch.argmax(next_token_logits, dim=-1)\n",
    "model_inputs['input_ids'] = torch.cat([model_inputs['input_ids'], next_token[:, None]], dim=-1)\n",
    "model_inputs[\"attention_mask\"] = torch.cat([model_inputs['attention_mask'], torch.tensor([[1]])], dim=-1)\n",
    "print(tokenizer.decode(model_inputs['input_ids'][0]))"
   ],
   "id": "f9987c1a0a2e7b4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swimming at the beach is a great way\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:27:07.715956Z",
     "start_time": "2025-09-16T14:27:07.403043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_generate = model.generate(**model_inputs, max_length=20, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(output_generate[0]))"
   ],
   "id": "273c3a5b599bd00d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swimming at the beach is a great way to get a little extra energy.\n",
      "\n",
      "The beach\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
